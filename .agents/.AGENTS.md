# daplug-s3 Usage Guide for Agents

This document explains how to use the `daplug_s3` library as a consumer. It focuses on the public API exported through `daplug_s3/__init__.py`.

---

## Getting Started
```python
from daplug_s3 import adapter

s3 = adapter(
    endpoint="https://s3.us-east-1.amazonaws.com",
    bucket="my-app-bucket",
    aws_access_key_id="AKIA...",
    aws_secret_access_key="secret",
    region="us-east-1",
    sns_arn="arn:aws:sns:...:topic",
    sns_endpoint="https://sns.us-east-1.amazonaws.com",
)
```
All keyword arguments map to S3 or SNS configuration. Only `bucket`, `aws_access_key_id`, `aws_secret_access_key`, and `region` are strictly required for S3 operations.

| Adapter kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `endpoint` | `str \| None` | No | Custom S3 endpoint (e.g., LocalStack). |
| `bucket` | `str` | Yes | Target bucket for all operations. |
| `aws_access_key_id` | `str` | Yes | IAM access key. |
| `aws_secret_access_key` | `str` | Yes | IAM secret key. |
| `region` | `str` | Yes | AWS region. |
| `sns_arn` | `str` | No | SNS topic ARN for publish events. |
| `sns_endpoint` | `str` | No | SNS endpoint override. |
| `sns_attributes` | `dict[str, str | int | float | bool]` | No | Default SNS attributes merged for publish calls. |

Every method accepts keyword arguments only. Below sections explain each operation.

---

## `create(**kwargs)` / `put(**kwargs)`
Alias; both store objects to S3 and publish an event.

```python
payload = {"type": "invoice", "id": 123}
s3.put(s3_path="docs/invoice-123.json", data=payload, json=True)
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Key within the configured bucket. |
| `data` | `bytes \| str \| JSON` | Yes | Body to write. |
| `json` | `bool` | No (default `False`) | If `True`, data is JSON-encoded with `jsonpickle`. |
| `encode` | `bool` | No (default `True`) | Encodes strings to UTF-8 bytes. Set `False` when passing `bytes`. |
| `public_read` | `bool` | No (default `False`) | Grants `public-read` ACL when `True`. |

**Behavior:**
- Automatically sets ACL (`private` vs `public-read`).
- JSON payloads become stable deterministic strings.
- Always publishes a presigned URL via `BaseAdapter.publish` (SNS hook).

---

## `upload_stream(**kwargs)`
Uploads large content through a buffered stream.

```python
from pathlib import Path
with Path("manual.pdf").open("rb") as fh:
    s3.upload_stream(s3_path="files/manual.pdf", io=fh, public_read=True)
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Destination key. |
| `io` | file-like object | Yes* | File-like object to read. |
| `data` | `bytes` | Alternative | Raw bytes (used when `io` is absent). |
| `threshold` | `int` | No (`10000`) | Multipart threshold for boto3 TransferConfig. |
| `concurrency` | `int` | No (`4`) | Max parallel upload workers. |
| `public_read` | `bool` | No | Public ACL toggle. |

> Provide either `io` **or** `data`. After upload, a presigned URL is published.

---

## `read(**kwargs)` / `get(**kwargs)`
Retrieve an object. `read` is a thin alias to `get`.

```python
text = s3.read(s3_path="docs/invoice-123.json")
```

| Kwarg | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `s3_path` | `str` | Yes | — | Key to fetch. |
| `json` | `bool` | No | `False` | When `True`, body is decoded via `jsonpickle`. |
| `decode` | `bool` | No | `True` | If `False`, returns raw boto3 response object. |

Return value: decoded string (default), JSON structure, or raw response based on kwargs.

---

## `download(**kwargs)`
Fully downloads an object to local disk.

```python
target = s3.download(s3_path="files/manual.pdf", download_path="/tmp/manual.pdf")
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Remote key. |
| `download_path` | `str` | Yes | Absolute/relative path to write. |

Ensures containing directories exist and returns the destination path string.

---

## `multipart_upload(**kwargs)`
Sends multiple parts manually (useful for prechunked data).

```python
chunks = [b"first", b"second", b"third"]
s3.multipart_upload(s3_path="archives/data.bin", chunks=chunks)
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Target key. |
| `chunks` | `Sequence[bytes]` | Yes | Ordered data chunks. |

Automatically creates the multipart upload, uploads each chunk with incrementing part numbers, completes the upload, and publishes a presigned URL.

---

## `create_public_url(**kwargs)`
Generates an unsigned perpetual HTTPS URL (public ACL required).

```python
url = s3.create_public_url(s3_path="files/manual.pdf")
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Object key. |

Uses a client configured with `signature_version=botocore.UNSIGNED` to emit a URL that never expires. Only works for `public-read` objects.

---

## `create_presigned_read_url(**kwargs)`
Generates time-limited signed URLs.

```python
url = s3.create_presigned_read_url(s3_path="docs/invoice-123.json", expiration=900)
```

| Kwarg | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `s3_path` | `str` | Yes | — | Object key. |
| `expiration` | `int` | No | `3600` | Lifetime in seconds. |

---

## `create_presigned_post_url(**kwargs)`
Creates POST upload policies.

```python
policy = s3.create_presigned_post_url(
    s3_path="uploads/raw.txt",
    required_fields={"acl": "private"},
    required_conditions=[["content-length-range", 0, 1048576]],
    expiration=600,
)
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Key to upload to. |
| `required_fields` | `dict[str, str]` | No | Pre-populated HTML form fields (e.g., ACL). |
| `required_conditions` | `list[dict[str, str]]` | No | Additional S3 POST policy conditions. |
| `expiration` | `int` | No (`3600`) | Policy lifetime in seconds. |

Return value matches boto3’s `generate_presigned_post` structure (`{"url": ..., "fields": {...}}`).

---

## `object_exist(**kwargs)`
Boolean existence check.

```python
if not s3.object_exist(s3_path="docs/invoice-999.json"):
    raise LookupError("missing file")
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Key to inspect. |

Returns `True` when the object loads successfully, `False` on 404, and re-raises other `ClientError`s.

---

## Listing Helpers
### `list_dir_subfolders(**kwargs)`
```python
folders = s3.list_dir_subfolders(dir_name="reports/")
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `dir_name` | `str` | Yes | Prefix ending with `/`. |

Returns a list of folder prefixes (e.g., `['reports/2023/', 'reports/2024/']`).

### `list_dir_files(**kwargs)`
```python
recent = s3.list_dir_files(dir_name="reports/", date=datetime.utcnow())
```

| Kwarg | Type | Required | Default | Description |
| --- | --- | --- | --- | --- |
| `dir_name` | `str` | Yes | — | Prefix to scan.
| `date` | `datetime` | No | `None` | When provided, only keys modified after this timestamp are returned.

Outputs a list of object keys.

---

## `rename_object(**kwargs)`
Copy and delete in one helper.

```python
s3.rename_object(old_file_name="logs/old.txt", new_file_name="logs/new.txt")
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `old_file_name` | `str` | Yes | Existing key. |
| `new_file_name` | `str` | Yes | New key. |

Uses S3 copy + delete. Make sure both objects reside in the same bucket.

---

## `delete(**kwargs)`
Removes an object.

```python
s3.delete(s3_path="archives/data.bin")
```

| Kwarg | Type | Required | Description |
| --- | --- | --- | --- |
| `s3_path` | `str` | Yes | Key to remove. |

Returns the raw boto3 `delete_object` response.

---

## Publish Data Contract
Every write-like method (`put`, `upload_stream`, `multipart_upload`) emits SNS payloads via `BaseAdapter.publish` with the shape:
```python
{"presigned_url": s3.create_presigned_read_url(**kwargs)}
```
There is no longer a `publish` flag—publishing is always enabled.

---

## Local Testing Pointers for Consumers
- Use `S3_ENDPOINT=http://localhost:4566` plus LocalStack to mimic AWS.
- Provide mock AWS credentials (any non-empty strings). Example fixture used in integrations:
  ```python
  adapter(
      endpoint="http://localhost:4566",
      bucket="integration",
      aws_access_key_id="test",
      aws_secret_access_key="test",
      region="us-east-1",
  )
  ```
- Remember to create the bucket before issuing writes when using custom endpoints.

---

Refer back to this document whenever you need a reminder of which arguments each method accepts or how to exercise specific behaviors.
